{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on concurrent FP-Growth implementation in Python\n",
    "> Spampinato Marco, March 25th, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "### Frequent itemsets mining\n",
    "Frequent Itemsets Mining (FIM) is, after preprocessing, often the first topic discussed in Data Mining courses around the world, as its striking importance in solving problems such as _market basket analysis_, _recommendation systems_ and many more data mining problems.\n",
    "\n",
    "The classic goal of FIM applied in market basket analysis is to find those items which are often found together in same transactions, so to then infer association rules, such as the classic:\n",
    "$$Diapers \\longrightarrow Beer$$\n",
    "In order to infer such association, it's necessary that many transactions contain both _Beer_ and _Diapers_, and that's what a FIM algorithm solves.\n",
    "\n",
    "There are three kinds of algorithms that searches for frequent itemsets:\n",
    "- **Apriori**, uses a generational approach by computing candidates.\n",
    "- **ECLAT**, an alternative of Apriori which generates candidates using TIDs.\n",
    "- **FP-Growth**, a method based on prefix tree mining, of which this project provides an implementation, it is supposed to be faster than Apriori.\n",
    "\n",
    "### FP-Growth algorithm\n",
    "FP-Growth is a fun algorithm, as mentioned before, it involves in mining a prefix tree, which represents the whole database of transaction compressed.\n",
    "\n",
    "Roughly, one can sum up the FP-Growth algorithm in three steps:\n",
    "1. Frequent items collection.\n",
    "    - A linear scan over the database is performed to collect those items which support is greater or equal than the minimum one.\n",
    "    - The items then get sorted in order descending order of support.\n",
    "2. FP-Tree construction.\n",
    "    - A linear scan over the database constructs the FP-Tree, which represents a compressed database.\n",
    "3. FP-Tree mining.\n",
    "    - By projecting the tree bottom-up by item, frequent itemsets are collected by traversing the paths upwards.\n",
    "\n",
    "### Motivations and goals\n",
    "During class we had the opportunity to practice with both Apriori and FP-Growth algorithms.  \n",
    "Most, if not all, of us students used the _mlxtend_ library which provided implementations for both algorithms along with association rules extraction.\n",
    "\n",
    "One observation on those practices is that neither of the provided implementations used more than one computational unit, that's it, they are not using all our CPU's cores, which in the previous years doubled or quadrupled in counts, to our benefits and content.\n",
    "\n",
    "And while Apriori could be tweaked not to allocate illegaly huge amounts of RAM, that was not the case for FP-Growth, which could take even up to 40GB of memory, leading to nasty thrashing if the tree couldn't fit in memory.\n",
    "\n",
    "Thus an alternative implementation of FP-Growth has been proposed and accepted as project exam, with the following goals:\n",
    "- The implementation must take advantage of multi-core processors.\n",
    "- The implementation must use less memory.\n",
    "\n",
    "Concurrent programming is achieved by means of multi-processing, due to limits on CPython's runtime.\n",
    "\n",
    "## Trial and error constructing the FP-Tree\n",
    "I talked big when I proposed the project, to my detriment.\n",
    "\n",
    "Different research papers on novel FP-Growth methods have been explored, nonetheless due to technical language barrier, I failed to understand one [1], had a totally different interpretation, and took me busy for a while.\n",
    "\n",
    "### Partitioning algorithm\n",
    "[1] describes a method of constructing the FP-Tree by _splitting_ the database recursively into sections: my fouled interpretation of that has been a recursive partitioning of the transaction database from the most to the least frequent item, thus creating a tree of partitions.\n",
    "\n",
    "The algorithm is implemented in `old_code/old/algorithm2.py` and its precedent versions, along with a failed multi processing implementation, it can roughly be summarized with:\n",
    "\n",
    "```txt\n",
    "root = root node spanning the whole dataset\n",
    "levels = { {root} }\n",
    "right_parititions = {}\n",
    "\n",
    "for each frequent item in descending order of support:\n",
    "    next_level = {}\n",
    "    next_right = {}\n",
    "    for each partition in previous level U right_partitions:\n",
    "        left = transactions having item\n",
    "        right = transactions not having item\n",
    "        add left to next_level\n",
    "        add right to next_right\n",
    "\n",
    "    add next_level to levels\n",
    "    swap right_partitions with next_right\n",
    "\n",
    "return levels\n",
    "```\n",
    "\n",
    "While tricks and hacks have been used to have this peform as fast as possible, it has to scan the database multiple times, thus while the result is correct, it is too slow.\n",
    "\n",
    "A concurrent prototype has been coded, but due to restrictions in Python's concurrency implementation, it has been promptly abandoned.\n",
    "\n",
    "Although not optimal for use in standard processors, the algorithm should be tested on GPUs, where standard FP-Tree construction algorithms may not even be possible. \n",
    "\n",
    "### A more classic implementation\n",
    "I have decided to implement a more classic, FP-Tree as prefix tree, one transaction at a time.\n",
    "\n",
    "The algorithm, which is similar to the final implementation, has been definitely faster than the partition method, but had the same side effect as _mlxtend_'s one of using too much memory.\n",
    "\n",
    "From the partition method, I brought forward the idea of left and right.\n",
    "\n",
    "The following database:\n",
    "\n",
    "| TID | Transaction items ordered by frequent item |\n",
    "|-----|--------------------------------------------|\n",
    "| 100 | f, c, a, m, p                              |\n",
    "| 200 | f, c, a, b, m                              |\n",
    "| 300 | f, b                                       |\n",
    "| 400 | c, b, p                                    |\n",
    "| 500 | f, c, a, m, p                              |\n",
    "\n",
    "Can be virtually represented with a pivot table:\n",
    "\n",
    "| f | c | a | b | m | p |\n",
    "|---|---|---|---|---|---|\n",
    "| 1 | 1 | 1 | 0 | 1 | 1 |\n",
    "| 1 | 1 | 1 | 1 | 1 | 0 |\n",
    "| 1 | 0 | 0 | 1 | 0 | 0 |\n",
    "| 0 | 1 | 0 | 1 | 0 | 1 |\n",
    "| 1 | 1 | 1 | 0 | 1 | 1 |\n",
    "\n",
    "Whenever an item is present in transaction, a left node is used, else a right node.\n",
    "\n",
    "On real databases, the pivot table would be very sparse, thus leading to a huge amount of right nodes if no compression is used, and longer traversals time.  \n",
    "Additionally, Python objects would reserve some more memory for metadata and garbage collection, thus leading to more memory usage than expected.\n",
    "\n",
    "The final implementation will address these issues.\n",
    "\n",
    "## FP-Growth implementation\n",
    "The implemented FP-Growth uses the standard, one at a time, approach to build the tree, and computes maximal frequent itemsets.\n",
    "\n",
    "A frequent item preprocessor is used to compute frequent items through the _fit_ method, and _transform_ is used to process each transaction before feeding it to the FP-Tree for construction, items are relabeled.\n",
    "\n",
    "The FP-Tree does not uses objects as nodes, instead allocating a node means allocating its attributes in a series of arrays, no additional metadata or garbage collection book-keeping is needed, a node is represented by its index.\n",
    "Memory is also contiguous, thus more cache friendly.\n",
    "\n",
    "Right nodes, which are logically similar to edges, are compressed:\n",
    "A right edge denotes an edge from a left node to the immediate antecedent of the next, some fairly complex logic is used to split and traverse right edges.\n",
    "\n",
    "Finally, the itemsets extraction works by recursive projection of each label's node.\n",
    "\n",
    "In multiprocessing, the itemsets extraction part is dispatched to child processes.\n",
    "\n",
    "### Preprocessing\n",
    "Preprocessing is done by class `FrequentItemPreprocessor` (FIP), its constructor accepts a required `min_support` parameter and `max_support` parameter; it has two methods:\n",
    "- `fit` accepts a sequence of transactions and will construct the headers table data.\n",
    "- `transform` accept a transaction and returns a relabeled transaction, ordered in order of decreasing support.\n",
    "- `to_item` and `to_items` transform either a single label and a list of labels back to item or items. \n",
    "\n",
    "The `FrequentItemPreprocessor` is used internally.\n",
    "\n",
    "### FP-Tree\n",
    "The FP-Tree is implemented by class `FlatFPTree`.\n",
    "\n",
    "The constructor accepts a `FrequentItemPreprocessor` and would then initialize class state, the next node id and node attributes arrays ( type, label, count, parent, left, right ) to empty arrays.  \n",
    "Finally, for each label, a list of nodes is initialized with a first empty node, which will then be used as de factor root for every transaction starting with such label.\n",
    "\n",
    "A set of accessors and setters are available for easier node manipulation.\n",
    "\n",
    "#### Adding a transaction\n",
    "A transaction is added via `add_transaction`, the transaction is first tramsformed via the FIP, and tested for a valid length.\n",
    "\n",
    "A private implementation of `add_transaction` will start by selecting the first node represented by the first label of the transformed transaction, will then increment the node uses, and for each label, traverse the tree and increment each label's node uses.\n",
    "\n",
    "Traversing is done by the `traverse` method, which will traverse, split and create edges and nodes at need, roughly the method pseudocode is:\n",
    "```txt\n",
    "if destination label is immediate successor of source label:\n",
    "    return the node on the left of node, create if needed\n",
    "else:\n",
    "    right_destination_label = immediate predecessor of destination label\n",
    "    right = edge on the right of node\n",
    "    if right does not exists:\n",
    "        create right edge\n",
    "        create and return right edge's left node \n",
    "    else:\n",
    "        if right edges's label is greater than right_destination_node:\n",
    "            split right edge\n",
    "            return right edge\n",
    "        else:\n",
    "            right = first existing right edge before right_destination_label\n",
    "            traverse right\n",
    "```\n",
    "#### Tree projection and mining\n",
    "Tree projection is done recursively by `project_and_mine_tree`, for each label:\n",
    "1. Upwards paths from each label's node are computed.\n",
    "    - If paths length is one, construct an itemset from that path.\n",
    "    - If paths lenght is greater than one, recursively construct and mine a new tree using paths as databases, collect frequent itemsets.\n",
    "2. Return collected itemsets along with the header of label.\n",
    "\n",
    "#### Itemset extraction and concurrency\n",
    "Method `extract_itemsets` of the FP-Tree will select between two paths of execution, depending on `max_workers` params.\n",
    "\n",
    "If `max_workers = 0`, itemsets extraction is peformed on the main process.\n",
    "\n",
    "If `max_workers > 0`, a pool of child processes is spawned by `ProcessPoolExecutor`, they are initialized with a copy of the original FP-Tree.  \n",
    "An array of indices to labels is computed and shuffled, then naively split into a grid of `max_workers` chunks, ultimately dispatched to the executor.  \n",
    "The results are then merged together.\n",
    "\n",
    "Itemsets extraction is ultimately delegated by running `project_tree` for each label in the workset.\n",
    "\n",
    "#### Facade\n",
    "Function `fpgrowth_mp` is provided as facade for the entire algorithm, it accepts the minimum support parameter, the transaction database as list of transactions, an optional number of max workers.\n",
    "\n",
    "By default, max workers is set as the number of threads of the host computer.  \n",
    "If max workers is set to zero the algorithm will run only in the main process.\n",
    "\n",
    "Function `fpgrowth` is alias `fpgrowth_mp` with `max_workers` set to zero, so, to run on main process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performances\n",
    "The performance is evaluated with different datasets and against both _mlxtend_'s _Apriori_ and _FP-Growth_ implementations.\n",
    "\n",
    "Following are the used dataset and eventual copyrights.\n",
    "> TODO: http://fimi.uantwerpen.be/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
